# End-of-Chapter Quiz

Chapter 1.ì„ ë§ˆë¬´ë¦¬í•˜ë©´ì„œ ê·¸ê°„ ë°°ìš´ ë‚´ìš©ë“¤ì„ í† ëŒ€ë¡œ ê°„ë‹¨í•œ í€´ì¦ˆë¥¼ í’€ì–´ë³´ì! 
ê° ë¬¸ì œì˜ ë‹µì€ ë§ˆì§€ë§‰ì— ìˆìŠµë‹ˆë‹¤.

#### 1. Hubì—ì„œ 'roberta-large-mnli'ì˜ checkpointë¥¼ ì°¾ì•„ë³´ì„¸ìš”. ì´ ëª¨ë¸ì€ ì–´ë–¤ taskë¥¼ ìˆ˜í–‰í–ˆì„ê¹Œìš”?

- Summarization(ìš”ì•½)
- Text classification(ë¶„ë¥˜)
- Text generation(ìƒì„±)

#### 2. ë‹¤ìŒì˜ ì½”ë“œê°€ ë‚´ë†“ì„ ê²°ê³¼ëŠ”?

``` python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

- ë¬¸ì¥ì´ 'ê¸ì •'ì¸ì§€ 'ë¶€ì •'ì¸ì§€ì— ëŒ€í•œ ê°’ì„ ë‚˜íƒ€ë‚´ì„œ ë¶„ë¥˜
- ì´ ë¬¸ì¥ì„ ì™„ì„±ì‹œí‚¬ ë¬¸ì¥ 'ìƒì„±'
- ì‚¬ëŒ, ê¸°ê´€, ì¥ì†Œ ì¤‘ ì–´ë””ì— ì†í•˜ëŠ” ë‹¨ì–´ì¸ì§€ ì¶œë ¥

#### 3. ì½”ë“œì—ì„œ '...' ë¶€ë¶„ì„ ë¬´ì—‡ìœ¼ë¡œ ë°”ê¿”ì•¼ í• ê¹Œ?

``` python
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

- This <mask> has been waiting for you.
- This [MASK] has been waiting for you.
- This man has been waiting for you.
  
#### 4. ì™œ ì´ ì½”ë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì„ê¹Œ?

``` python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```
  
- ì´ pipelineì€ textë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ì£¼ì–´ì§€ëŠ” labelë¥¼ í•„ìš”ë¡œ í•œë‹¤.
- ì´ pipelineì€ í•œ ê°œê°€ ì•„ë‹Œ, ì—¬ëŸ¬ ê°œì˜ ë¬¸ì¥ì„ í•„ìš”ë¡œ í•œë‹¤.
- ğŸ¤— Transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ê³ ì¥ë‚¬ë‹¤!
- ì´ pipelineì€ ë”ìš± ê¸´ ì…ë ¥ì„ í•„ìš”ë¡œ í•œë‹¤. ì´ê±´ ë„ˆë¬´ ì§§ì–ì•„!
  
#### 5. 'transfer learning'ì˜ ì˜ë¯¸ëŠ”?
  
- ë˜‘ê°™ì€ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ pretrained ëª¨ë¸ì˜ ì§€ì‹ì„ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì „ì´ì‹œí‚¨ë‹¤.
- ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¡œ ë‘ ë²ˆì§¸ ëª¨ë¸ë„ ì‘ë™ì‹œí‚¤ê¸° ìœ„í•´ pretrained ëª¨ë¸ì˜ ì§€ì‹ì„ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì „ì´ì‹œí‚¨ë‹¤.
- ë‘ ë²ˆì§¸ ëª¨ë¸ë„ ì²« ë²ˆì§¸ ëª¨ë¸ì˜ architectureì™€ ë˜‘ê°™ì´ ë§Œë“¤ê¸° ìœ„í•´ pretrained ëª¨ë¸ì˜ ì§€ì‹ì„ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì „ì´ì‹œí‚¨ë‹¤.
  
#### 6. language modelì€ pretrainingí•  ë•Œ, ë³´í†µ labelì´ í•„ìš”ì—†ë‹¤.
  
- True
- False
  
#### 7. 'model', 'architecture', 'weights'ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•œ ë¬¸ì¥ì„ ê³ ë¥´ì‹œì˜¤.
  
- modelì´ ì§€ì–´ì§€ë©´, architectureê°€ ì´ ëª¨ë¸ì˜ ì²­ì‚¬ì§„ì´ê³ , weightsëŠ” ê·¸ ì•ˆì— ì‚¬ëŠ” ì‚¬ëŒë“¤ì´ë‹¤.
- architectureëŠ” modelì„ ë§Œë“¤ê¸° ìœ„í•œ ì§€ë„ ê°™ì€ ì¡´ì¬ì´ê³ , weightsëŠ” ì§€ë„ì— í‘œì‹œëœ ë„ì‹œ ê°™ì€ ì¡´ì¬ì´ë‹¤.
- architectureëŠ” modelì„ ë§Œë“¤ê¸° ìœ„í•œ ìˆ˜í•™ì  í•¨ìˆ˜ì˜ ì—°ì†ì´ê³ , weightsëŠ” ê·¸ëŸ¬í•œ í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ì´ë‹¤.
  
#### 8. ë¬¸ì¥ ìƒì„±ì„ ìœ„í•´ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?
  
- Encoder model
- Decoder model
- Seq-to-Seq model
  
#### 9. ë¬¸ì¥ ìš”ì•½ì„ ìœ„í•´ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?
  
- Encoder model
- Decoder model
- Seq-to-Seq model
  
#### 10. íŠ¹ì • labelì— ë”°ë¼ ë¬¸ì¥ ë¶„ë¥˜ ìœ„í•´ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?
  
- Encoder model
- Decoder model
- Seq-to-Seq model

  
  
  
  
  
ì •ë‹µ
1. 2
2. 3
3. 2
4. 1
5. 2
6. True
7. 3
8. 2
9. 3
10. 1
