# Fine-tuning a model with the Trainer API

ğŸ¤— TransformerëŠ” Trainer í´ë˜ìŠ¤ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨, pre-trained modelì— ìì‹ ë§Œì˜ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ fiëª¨ë‘ ne-tuneí•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡Œë‹¤.
ì§€ë‚œ ì„¹ì…˜ì—ì„œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ëª¨ë‘ ëëƒˆë‹¤ë©´, Trainerì„ ì •ì˜í•˜ê¸° ê¹Œì§€ ëª‡ ë‹¨ê³„ ë‚¨ì§€ ì•Šì•˜ë‹¤.
ê°€ì¥ ì–´ë ¤ìš´ ë¶€ë¶„ì€ Trainer.train()ì„ ì‹¤í–‰í•  í™˜ê²½ì„ ì¤€ë¹„í•˜ëŠ” ê²ƒì¼ ê²ƒì´ë‹¤.
ì™œëƒí•˜ë©´, CPUì—ì„œëŠ” ë§¤ìš° ì²œì²œíˆ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì´ë‹¤.
ê·¸ë ‡ë‹¤ê³  GPUê°€ ì—†ë‹¤ê³  í•´ì„œ ë„ˆë¬´ ê±±ì •í•˜ì§€ëŠ” ë§ˆë¼, ìš°ë¦¬ì—ê²ŒëŠ” Colabì˜ GPUì™€ TPUê°€ ìˆìœ¼ë‹ˆ! ğŸ˜‰

ì•„ë˜ì˜ ì½”ë“œ ì˜ˆì‹œëŠ” ì´ì „ ì„¹ì…˜ì—ì„œ ì‹¤í–‰ëœ ëª¨ë“  ì½”ë“œì˜ ì¢…í•© ë²„ì „ì´ë‹¤. í•œ ë²ˆ ì§šê³  ë„˜ì–´ê°ˆ ìˆ˜ ìˆê¸¸ ë°”ë€ë‹¤.

``` python
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### Training

Trainerì„ ì •ì˜í•˜ê¸° ì „ì— ì •ì˜í•´ì•¼ í•˜ëŠ” í´ë˜ìŠ¤ëŠ” TrainingArguments í´ë˜ìŠ¤ì´ë‹¤.
ì´ í´ë˜ìŠ¤ëŠ” Trainerê°€ í•™ìŠµê³¼ í‰ê°€ì— ì‚¬ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤.
ìš°ë¦¬ê°€ ì§€ì •í•´ì•¼ í•˜ëŠ” ì¸ìˆ˜ëŠ” ëª¨ë¸ì´ ì–´ëŠ ìœ„ì¹˜ì— ì €ì¥ë  ì§€ì™€ checkpoint ë¿ì´ë‹¤.
ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ fine-tuningì„ ìœ„í•´ ì˜ ì‘ë™í•˜ëŠ” ê¸°ë³¸ê°’ì„ ê·¸ëŒ€ë¡œ ë‘”ë‹¤.

``` python
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

ê·¸ ë‹¤ìŒ ë‹¨ê³„ëŠ” modelì„ ì •ì˜í•˜ëŠ” ê²ƒì´ë‹¤.
ì´ì „ ì±•í„°ì—ì„œì²˜ëŸ¼, AutoModelForSequenceClassification í´ë˜ìŠ¤ì— ë‘ ê°œì˜ ë¼ë²¨ì„ ì ìš©í•´ì„œ ì‚¬ìš©í•  ê²ƒì´ë‹¤.

``` python
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

Chapter 2.ì™€ ë‹¬ë¦¬, ì´ pre-trained modelì„ ì‹¤í–‰í•˜ëŠ”ë° ê²½ê³ ê°€ ëœ° ìˆ˜ë„ ìˆë‹¤.
ì´ëŠ” BERTê°€ ë¬¸ì¥ ìŒì„ ë¶„ë¥˜í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ pre-trainë˜ì§€ ì•Šì•„ì„œ, pre-trained modelì˜ headê°€ ì œê±°ë˜ê³ , sequence classificationì— ì•Œë§ëŠ” ì í•©í•œ ìƒˆë¡œìš´ headê°€ ëŒ€ì‹ ì— ì¶”ê°€ëœë‹¤.
ê²½ê³ ë“¤ì€ ëª‡ ê°œì˜ ê°€ì¤‘ì¹˜ê°€ ì‚¬ìš©ë˜ì§€ ì•Šê³ , ë‹¤ë¥¸ ê°’ë“¤ì€ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
ì´ê²ƒì€ ìš°ë¦¬ê°€ ì§€ê¸ˆ í•˜ë ¤ê³  í•˜ëŠ” ê²ƒê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª¨ë¸ì„ í›ˆë ¨í•˜ë„ë¡ ê²©ë ¤í•¨ìœ¼ë¡œì¨ ê²°ë¡ ì„ ë‚´ë¦°ë‹¤.

ìš°ë¦¬ì˜ modelì„ ê°–ê²Œ ë˜ë©´, ì§€ê¸ˆê¹Œì§€ êµ¬ì„±ëœ ëª¨ë“  ê°ì²´ë¥¼ ì „ë‹¬í•˜ì—¬ Trainerì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤.
ê°ì²´: model, training_args, training & validation set, data_collator, tokenizer

``` python
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

ìœ„ì˜ ì½”ë“œì—ì„œ í•œ ê²ƒì²˜ëŸ¼ tokenizerì„ ì‚¬ìš©í•˜ë©´, Trainerì— ì˜í•´ ì‚¬ìš©ëœëŠ data_collatorì˜ ê¸°ë³¸ê°’ì€ ì´ì „ì— ì •ì˜í–ˆë˜ DataCollatorWithPaddingì¼ ê²ƒì´ë‹¤.
ë”°ë¼ì„œ, data_collator=data_collator ì¤„ì„ ìŠ¤í‚µí•´ë„ ëœë‹¤. 

modelì„ ìš°ë¦¬ì˜ datasetì— fine-tuneí•˜ê¸° ìœ„í•´, ë‹¨ì§€ Trainerì˜ train() methodë§Œì„ ë¶ˆëŸ¬ì˜¤ë©´ ëœë‹¤.

``` python
trainer.train()
```

ì´ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ëª¨ë¸ì€ fine-tuningì„ í•˜ë©´ì„œ, ë§¤ 500 ë‹¨ê³„ ë§ˆë‹¤ training lossë¥¼ ê¸°ë¡í•œë‹¤.
í•˜ì§€ë§Œ, ì´ ê°’ì´ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ê³  ìˆëŠ”ì§€ ë§í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤.
ì´ëŠ” ì™œëƒí•˜ë©´,

1. Trainerì—ê²Œ evaluation_strategyë¥¼ ì„¤ì •í•´ì„œ í•™ìŠµ ì¤‘ì— í‰ê°€ë¥¼ ì§„í–‰í•˜ë¼ê³  ëª…ë ¹í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤.
2. Trainerì—ê²Œ í‰ê°€ë¥¼ ì§„í–‰í•  ë•Œì‚¬ìš©ë  metricì¸ compute_metrics()ë¥¼ ì œê³µí•´ì£¼ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤.

###  Evaluation

ì´ì œ, ì–´ë–»ê²Œ ìœ ìš©í•œ compute_metrics() í•¨ìˆ˜ë¥¼ ë§Œë“œëŠ”ì§€ë¥¼ ì•Œì•„ë³´ê³ , ë‹¤ìŒì˜ í•™ìŠµ ë•Œ ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ë³´ì.
compute_metrics() í•¨ìˆ˜ëŠ” ë¬´ì¡°ê±´ EvalPrediction objectë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ë¬¸ìì—´ì„ ì‹¤ìˆ˜í˜•ì— ë§¤í•‘í•˜ëŠ” dictionaryë¥¼ ë°˜í™˜í•œë‹¤.
modelì—ì„œ ì˜ˆì¸¡ì„ ì–»ìœ¼ë ¤ë©´, Trainer.predict() ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.

``` python
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

``` python
(408, 2) (408,)
```

predict() methodì˜ ì¶œë ¥ì€ predictions, label_ids, metricsë¥¼ í¬í•¨í•˜ê³  ìˆëŠ” ë˜ë‹¤ë¥¸ íŠœí”Œì´ë‹¤.
metrics í•„ë“œëŠ” datasetì´ ì§€ë‚˜ê°„ lossë¿ë§Œ ì•„ë‹ˆë¼, time metricsë„ í¬í•¨í•˜ê³  ìˆë‹¤.
compute_metrics() í•¨ìˆ˜ë¥¼ ì™„ì„±ì‹œí‚¤ê³ , ì´ í•¨ìˆ˜ë¥¼ Trainerì— ë„£ì–´ì¤€ë‹¤.
ì´ë¥¼ í†µí•´ Trainer ë˜í•œ compute_metrics()ì— ì˜í•´ ë°˜í™˜ëœ metricsë¥¼ ê°–ê²Œ ëœë‹¤.

ìœ„ì˜ ì½”ë“œ ì˜ˆì‹œì˜ ê²°ê³¼ë¥¼ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯ì´, predictionsëŠ” ëª¨ì–‘ì´ 408 x 2ì¸ 2ì°¨ì› ë°°ì—´ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
ì´ê²ƒë“¤ì€ ìš°ë¦¬ê°€ predict()ì— ì „ë‹¬í•œ ë°ì´í„°ì…‹ì˜ ê° ìš”ì†Œì— ëŒ€í•œ logitì´ë‹¤.
ì´ê²ƒë“¤ì„ ìš°ë¦¬ì˜ ë¼ë²¨ê³¼ ë¹„êµí•´ì•¼í•  predictionìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´, ë‘ ë²ˆì§¸ ì¶•ì—ì„œ ìµœëŒ€ê°’ì„ ê°€ì§„ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì™€ì•¼ í•œë‹¤.

``` python
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

ì´ì œ, ì´ predsë¥¼ ë¼ë²¨ê³¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤.
compute_metric() í•¨ìˆ˜ë¥¼ ë§Œë“¤ê¸° ìœ„í•´, ğŸ¤— Evaluate ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ metricì— ì˜ì¡´í•  ê²ƒì´ë‹¤.
MRPC datasetì„ ì—…ë¡œë“œí–ˆë˜ ê²ƒë§Œí¼ ì†ì‰½ê²Œ MRPCì™€ ê´€ë ¨ëœ metricì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.
ì´ë•Œ, evaluate.load() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.
ë°˜í™˜ëœ objectëŠ” metric calculationì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” compute() methodë¥¼ ê°€ì§€ê³  ìˆë‹¤.

``` python
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

``` python
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

ì •í™•í•œ ê²°ê´ê°’ì€ ë§¤ìš° ë‹¤ì–‘í•  ê²ƒì´ë‹¤.
ì™œëƒí•˜ë©´, ëœë¤í•˜ê²Œ ì´ˆê¸°í™”ëœ modelì˜ headì— ë”°ë¼ì„œ metricì´ ì–»ê²Œ ëœ ê°’ì€ ìƒì´í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
ìœ„ì˜ ê²°ê³¼ë¥¼ ë³´ë©´, modelì˜ validation setì— ëŒ€í•œ ì •í™•ë„ëŠ” 85.78%ì´ê³ , F1 scoreëŠ” 89.97ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
ì´ ë‘ metricì€ GLUE benchmarkì— ëŒ€í•œ MRPC datasetì˜ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.
BERT ë…¼ë¬¸ì˜ í‘œë¥¼ ë³´ë©´, base modelì— ëŒ€í•´ì„œ F1 scoreê°€ 88.9ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
ê·¸ ëª¨ë¸ì€ uncased ëª¨ë¸ì¸ë°, ìš°ë¦¬ì˜ ëª¨ë¸ì€ cased ëª¨ë¸ì´ë‹¤. ì´ëŠ” ìš°ë¦¬ì˜ ê²°ê´ê°’ì´ ë” ë‚«ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤!

ì´ ëª¨ë“  ê²ƒì„ í•˜ë‚˜ë¡œ í•©ì¹˜ë©´, compute_metrics() í•¨ìˆ˜ë¥¼ ì–»ê²Œ ëœë‹¤.

``` python
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

ê·¸ë¦¬ê³  í•œ epochì´ ëë‚  ë•Œë§ˆë‹¤ metricì˜ ê²°ê³¼ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´, compute_metrics() í•¨ìˆ˜ì™€ í•¨ê»˜ ìƒˆë¡­ê²Œ ì •ì˜ëœ Trainerì„ ì‚¬ìš©í•˜ë©´ ëœë‹¤.
ë‹¤ìŒì˜ ì½”ë“œë¥¼ ì‚´í´ë³´ì.

``` python
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

TrainingArgumentsì˜ evaluation_strategyë¥¼ 'epoch'ìœ¼ë¡œ ì…‹íŒ…í•´ì„œ ìƒˆë¡œìš´ ëª¨ë¸ì„ ë§Œë“¤ì—ˆë‹¤.
ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, ì´ë¯¸ í›ˆë ¨í•œ ëª¨ë¸ì˜ í›ˆë ¨ì„ ê³„ì†í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
ìƒˆë¡œìš´ í•™ìŠµì„ ì§„í–‰í•˜ê¸° ìœ„í•´ ë‹¤ì‹œ í•œ ë²ˆ ë‹¤ìŒì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì•¼ í•œë‹¤.

``` python
trainer.train()
```

ì´ë²ˆì—ëŠ”, training lossì™¸ì— ê° epochê°€ ëë‚  ë•Œ validation lossì™€ metircì„ ë³´ê³ í•œë‹¤.
ì´ë²ˆì—ë„ ë§ˆì°¬ê°€ì§€ë¡œ, ì •í™•í•œ accuracyì™€ F1 scoreëŠ” ì‚´ì§ ë‹¤ë¥¼ ê²ƒì´ë‹¤.
ì™œëƒí•˜ë©´, ëª¨ë¸ì˜ headê°€ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”ë˜ì—ˆê¸° ë•Œë¬¸ì´ë‹¤.

ì—¬ëŸ¬ ê°œì˜ GPUì™€ TPUì™€ í•¨ê»˜ Trainerë¥¼ ì‚¬ìš©í•˜ë©´, mixed-precision trainingê³¼ ê°™ì€ ì˜µì…˜ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
ì´ì— ê´€í•œ ëª¨ë“  ê²ƒì€ Chapter 10. ì—ì„œ ë‹¤ë£° ê²ƒì´ë‹¤.

ì´ë ‡ê²Œ í•´ì„œ Trainer APIë¥¼ ì‚¬ìš©í•´ì„œ fine-tuningì„ ì§„í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì„œë¡ ì´ ëë‚¬ë‹¤.
ì´ì— ëŒ€í•´ ì—¬ëŸ¬ NLP taskë¡œ ì‹¤ìŠµì„ ì§„í–‰í•˜ëŠ” ê±´ Chapter 7. ì—ì„œ ë‹¤ë¤„ë³¼ ì˜ˆì •ì´ì§€ë§Œ, ì´ì œ ìˆœìˆ˜í•œ PyTorchì—ì„œ ë˜‘ê°™ì´ ì§„í–‰í•´ë³´ë„ë¡ í•˜ì!
