# Fine-tuning a model with the Trainer API

🤗 Transformer는 Trainer 클래스를 제공함으로써, pre-trained model에 자신만의 데이터셋을 이용하여 fi모두 ne-tune할 수 있도록 만들어졌다.
지난 섹션에서 데이터 전처리를 모두 끝냈다면, Trainer을 정의하기 까지 몇 단계 남지 않았다.
가장 어려운 부분은 Trainer.train()을 실행할 환경을 준비하는 것일 것이다.
왜냐하면, CPU에서는 매우 천천히 실행되기 때문이다.
그렇다고 GPU가 없다고 해서 너무 걱정하지는 마라, 우리에게는 Colab의 GPU와 TPU가 있으니! 😉

아래의 코드 예시는 이전 섹션에서 실행된 모든 코드의 종합 버전이다. 한 번 짚고 넘어갈 수 있길 바란다.

``` python
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### Training

Trainer을 정의하기 전에 정의해야 하는 클래스는 TrainingArguments 클래스이다.
이 클래스는 Trainer가 학습과 평가에 사용할 하이퍼파라미터를 포함하고 있다.
우리가 지정해야 하는 인수는 모델이 어느 위치에 저장될 지와 checkpoint 뿐이다.
나머지는 기본 fine-tuning을 위해 잘 작동하는 기본값을 그대로 둔다.

``` python
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

그 다음 단계는 model을 정의하는 것이다.
이전 챕터에서처럼, AutoModelForSequenceClassification 클래스에 두 개의 라벨을 적용해서 사용할 것이다.

``` python
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

Chapter 2.와 달리, 이 pre-trained model을 실행하는데 경고가 뜰 수도 있다.
이는 BERT가 문장 쌍을 분류하는 방식으로 pre-train되지 않아서, pre-trained model의 head가 제거되고, sequence classification에 알맞는 적합한 새로운 head가 대신에 추가된다.
경고들은 몇 개의 가중치가 사용되지 않고, 다른 값들은 랜덤하게 초기화된다는 것을 의미한다.
이것은 우리가 지금 하려고 하는 것과 정확히 일치하는 모델을 훈련하도록 격려함으로써 결론을 내린다.

우리의 model을 갖게 되면, 지금까지 구성된 모든 객체를 전달하여 Trainer을 정의할 수 있다.
객체: model, training_args, training & validation set, data_collator, tokenizer

``` python
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)
```

위의 코드에서 한 것처럼 tokenizer을 사용하면, Trainer에 의해 사용된느 data_collator의 기본값은 이전에 정의했던 DataCollatorWithPadding일 것이다.
따라서, data_collator=data_collator 줄을 스킵해도 된다. 

model을 우리의 dataset에 fine-tune하기 위해, 단지 Trainer의 train() method만을 불러오면 된다.

``` python
trainer.train()
```

이 코드를 실행시키면 모델은 fine-tuning을 하면서, 매 500 단계 마다 training loss를 기록한다.
하지만, 이 값이 모델이 얼마나 잘 수행하고 있는지 말하는 것은 아니다.
이는 왜냐하면,

1. Trainer에게 evaluation_strategy를 설정해서 학습 중에 평가를 진행하라고 명령하지 않았기 때문이다.
2. Trainer에게 평가를 진행할 때사용될 metric인 compute_metrics()를 제공해주지 않았기 때문이다.

###  Evaluation

이제, 어떻게 유용한 compute_metrics() 함수를 만드는지를 알아보고, 다음의 학습 때 이 함수를 사용해보자.
compute_metrics() 함수는 무조건 EvalPrediction object를 입력으로 받고, 문자열을 실수형에 매핑하는 dictionary를 반환한다.
model에서 예측을 얻으려면, Trainer.predict() 명령어를 사용하면 된다.

``` python
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

``` python
(408, 2) (408,)
```

predict() method의 출력은 predictions, label_ids, metrics를 포함하고 있는 또다른 튜플이다.
metrics 필드는 dataset이 지나간 loss뿐만 아니라, time metrics도 포함하고 있다.
compute_metrics() 함수를 완성시키고, 이 함수를 Trainer에 넣어준다.
이를 통해 Trainer 또한 compute_metrics()에 의해 반환된 metrics를 갖게 된다.

위의 코드 예시의 결과를 보면 알 수 있듯이, predictions는 모양이 408 x 2인 2차원 배열인 것을 알 수 있다.
이것들은 우리가 predict()에 전달한 데이터셋의 각 요소에 대한 logit이다.
이것들을 우리의 라벨과 비교해야할 prediction으로 변환하기 위해, 두 번째 축에서 최대값을 가진 인덱스를 가져와야 한다.

``` python
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

이제, 이 preds를 라벨과 비교할 수 있다.
compute_metric() 함수를 만들기 위해, 🤗 Evaluate 라이브러리의 metric에 의존할 것이다.
MRPC dataset을 업로드했던 것만큼 손쉽게 MRPC와 관련된 metric을 불러올 수 있다.
이때, evaluate.load() 함수를 사용한다.
반환된 object는 metric calculation에 사용할 수 있는 compute() method를 가지고 있다.

``` python
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

``` python
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

정확한 결괏값은 매우 다양할 것이다.
왜냐하면, 랜덤하게 초기화된 model의 head에 따라서 metric이 얻게 된 값은 상이하기 때문이다.
위의 결과를 보면, model의 validation set에 대한 정확도는 85.78%이고, F1 score는 89.97인 것을 알 수 있다.
이 두 metric은 GLUE benchmark에 대한 MRPC dataset의 결과를 평가하기 위해 사용된다.
BERT 논문의 표를 보면, base model에 대해서 F1 score가 88.9인 것을 확인할 수 있다.
그 모델은 uncased 모델인데, 우리의 모델은 cased 모델이다. 이는 우리의 결괏값이 더 낫다고 할 수 있다!

이 모든 것을 하나로 합치면, compute_metrics() 함수를 얻게 된다.

``` python
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

그리고 한 epoch이 끝날 때마다 metric의 결과를 보고 싶다면, compute_metrics() 함수와 함께 새롭게 정의된 Trainer을 사용하면 된다.
다음의 코드를 살펴보자.

``` python
training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)
```

TrainingArguments의 evaluation_strategy를 'epoch'으로 셋팅해서 새로운 모델을 만들었다.
그렇지 않으면, 이미 훈련한 모델의 훈련을 계속하기 때문이다.
새로운 학습을 진행하기 위해 다시 한 번 다음의 코드를 실행해야 한다.

``` python
trainer.train()
```

이번에는, training loss외에 각 epoch가 끝날 때 validation loss와 metirc을 보고한다.
이번에도 마찬가지로, 정확한 accuracy와 F1 score는 살짝 다를 것이다.
왜냐하면, 모델의 head가 랜덤하게 초기화되었기 때문이다.

여러 개의 GPU와 TPU와 함께 Trainer를 사용하면, mixed-precision training과 같은 옵션도 사용할 수 있다.
이에 관한 모든 것은 Chapter 10. 에서 다룰 것이다.

이렇게 해서 Trainer API를 사용해서 fine-tuning을 진행하는 방법에 대한 서론이 끝났다.
이에 대해 여러 NLP task로 실습을 진행하는 건 Chapter 7. 에서 다뤄볼 예정이지만, 이제 순수한 PyTorch에서 똑같이 진행해보도록 하자!
