# Using pretrained models

Model Hub를 사용하면 적절한 모델을 간단하게 선택할 수 있으므로, 모든 다운스트림 라이브러리는 몇 줄의 코드로 모두 사용할 수 있다.
이 모델을 어떻게 사용하는지 간략하게 살펴보고, 다시 어떻게 커뮤니티에 공헌할 수 있는지 알아보도록 하자! 🔥

mask filling을 수행할 수 있는 프랑스어 기반의 model을 살펴보도록 하자.!

![camembert](https://user-images.githubusercontent.com/80087878/220233449-ff858fb7-29d2-4a4c-a8f0-f55a3af2dc57.gif)

이를 위해 camembert-base의 체크포인트를 선택해보자.
identifier camembert-base만 있으면, 이 모델을 사용할 수 있다!
이전의 챕터에서 봤던 것처럼, pipeline() 함수를 사용하여 이를 인스턴스화할 수 있다.

``` python
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
```

``` python
[
  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49091005325317383, 'token': 7200, 'token_str': 'délicieux'}, 
  {'sequence': 'Le camembert est excellent :)', 'score': 0.1055697426199913, 'token': 2183, 'token_str': 'excellent'}, 
  {'sequence': 'Le camembert est succulent :)', 'score': 0.03453313186764717, 'token': 26202, 'token_str': 'succulent'}, 
  {'sequence': 'Le camembert est meilleur :)', 'score': 0.0330314114689827, 'token': 528, 'token_str': 'meilleur'}, 
  {'sequence': 'Le camembert est parfait :)', 'score': 0.03007650189101696, 'token': 1654, 'token_str': 'parfait'}
]
```

위 코드처럼, pipeline을 사용해서 model을 불러오는 것은 매우 간단하다!
유일하게 확인해야 할 것은 task에 적합한 체크포인트를 선택하였느냐 이다.
예를 들어, 우리는 camembert-base 체크포인트의 fill-mask pipeline을 불러왔고, 이는 완벽하게 들어맞는다.
하지만, 만약 이 체크포인트에서 text-classification pipeline을 불러왔다면, camembert-base에는 적합한 task가 아니기 때문에, 좋은 결과를 보여줄 수가 없다.
Hugging Face Hub의 task selector을 사용해서 적절한 체크포인트를 선택하기를 추천한다.

![tasks](https://user-images.githubusercontent.com/80087878/220235997-c57e4e26-eef8-4a0e-8e0c-aec30ef3db2e.png)

또한, model architecture을 바로 사용해서 체크포인트를 인스턴스화 할 수 있다.

``` python
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
```

하지만, 그 대신에 Auto* 클래스를 사용하기를 추천한다.
왜냐하면, 이들은 설계상 architecture에 구애받지 않기 때문이다.
위의 코드 샘플은 CamemBERT architecture에서 로드할 수 있는 체크포인트로 사용자를 제한하지만, Auto* 클래스를 사용하면 체크포인트 전환이 간단해진다.

``` python
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
```
